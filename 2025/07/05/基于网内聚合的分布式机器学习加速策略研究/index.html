

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid_me.png">
  <link rel="icon" href="/img/fluid_me.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Wsdbybyd">
  <meta name="keywords" content="">
  
    <meta name="description" content="摘要  研究背景  大规模神经网络训练需求激增，单机训练效率低，而PS-Worker、AllReduce存在显著缺陷  PS-Worker：参数服务器带宽瓶颈限制规模扩展 AllReduce：通信延迟随节点数线性增长  网内聚合（ In-Network Aggregation） 成为了加速分布式机器学习训练的新方向  通过可编程交换机将梯度聚合卸载到网络层，减少主机计算压力">
<meta property="og:type" content="article">
<meta property="og:title" content="基于网内聚合的分布式机器学习加速策略研究">
<meta property="og:url" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/index.html">
<meta property="og:site_name" content="Wsdbybyd">
<meta property="og:description" content="摘要  研究背景  大规模神经网络训练需求激增，单机训练效率低，而PS-Worker、AllReduce存在显著缺陷  PS-Worker：参数服务器带宽瓶颈限制规模扩展 AllReduce：通信延迟随节点数线性增长  网内聚合（ In-Network Aggregation） 成为了加速分布式机器学习训练的新方向  通过可编程交换机将梯度聚合卸载到网络层，减少主机计算压力">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/1.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/2.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/3.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/4.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/5.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/6.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/7.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/8.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/9.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/10.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/11.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/12.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/13.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/18.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/19.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/14.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/15.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/16.png">
<meta property="og:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/17.png">
<meta property="article:published_time" content="2025-07-04T16:50:00.000Z">
<meta property="article:modified_time" content="2025-07-04T16:54:12.579Z">
<meta property="article:author" content="Wsdbybyd">
<meta property="article:tag" content="原创">
<meta property="article:tag" content="在网计算">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="网内聚合">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/1.png">
  
  
  
  <title>基于网内聚合的分布式机器学习加速策略研究 - Wsdbybyd</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"52Z5Ks9jpkkA8Nk9gIMDFgGD-gzGzoHsz","app_key":"CsGFqxm0pVH3GDRIHhk6l63y","server_url":"https://52z5ks9j.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Wsdbybyd</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="基于网内聚合的分布式机器学习加速策略研究"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-07-05 00:50" pubdate>
          2025年7月5日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          39 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">基于网内聚合的分布式机器学习加速策略研究</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="摘要">摘要</h1>
<ul>
<li>研究背景
<ul>
<li>大规模神经网络训练需求激增，单机训练效率低，而PS-Worker、AllReduce存在显著缺陷
<ul>
<li>PS-Worker：参数服务器带宽瓶颈限制规模扩展</li>
<li>AllReduce：通信延迟随节点数线性增长</li>
</ul></li>
<li>网内聚合（ In-Network Aggregation）
成为了加速分布式机器学习训练的新方向
<ul>
<li>通过可编程交换机将梯度聚合卸载到网络层，减少主机计算压力与网络流量</li>
<li>受限于交换机内存与计算能力</li>
</ul></li>
</ul></li>
<li>核心问题
<ul>
<li>问题1:
<ul>
<li>多任务争抢可编程交换机有限的内存资源，而导致网内聚合速度减慢和交换机内存利用率降低</li>
</ul></li>
<li>问题2
<ul>
<li>网内聚合扩展规模受限于可编程交换机有限的计算能力，大规模分布式训练中部署难度和成本高，
以及现有网内聚合扩展策略没有充分利用机内高带宽资源</li>
</ul></li>
</ul></li>
<li>解决方案
<ul>
<li>问题1：RA-INA混合同步算法
<ul>
<li>动态共享交换机内存，梯度分组后优先执行Ring-AllReduce</li>
<li>数据包到达交换机时批量抢占聚合器，成功则切换网内聚合</li>
</ul></li>
<li>问题2：CINA链式扩展策略
<ul>
<li>将 ToR（Top of Rack）交换机替换为可编程交换机，在 ToR
层形成一条网内聚合的链式流水线</li>
<li>利用机内高带宽，在机内进行 Ring-Reduce
将梯度聚合到机内主节点上，协同流水线进行机间的网内聚合</li>
</ul></li>
</ul></li>
<li>关键词
<ul>
<li>分布式机器学习</li>
<li>可编程交换机</li>
<li>网内聚合</li>
<li>多任务</li>
<li>大规模训练</li>
</ul></li>
</ul>
<h1 id="第一章-绪论">第一章 绪论</h1>
<ul>
<li>研究背景及意义
<ul>
<li>核心问题
<ul>
<li>大规模神经网络训练（如ChatGPT）需求激增，单机训练耗时过长（如1024块A100训练34天），分布式训练成关键技术。</li>
</ul></li>
<li>通信瓶颈
<ul>
<li>PS-Worker​
<ul>
<li>参数服务器（PS）节点多对一通信导致带宽瓶颈</li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/1.png" srcset="/img/loading.gif" lazyload alt="PS架构瓶颈">
<figcaption aria-hidden="true">PS架构瓶颈</figcaption>
</figure></li>
</ul></li>
<li>AllReduce
<ul>
<li>通信延迟随节点数线性增长，长环结构受限于最低带宽链路​</li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/2.png" srcset="/img/loading.gif" lazyload alt="AllReduce瓶颈">
<figcaption aria-hidden="true">AllReduce瓶颈</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li>网内聚合价值
<ul>
<li>通过可编程交换机卸载梯度聚合，减少网络流量与通信跳数，但受限于交换机内存与计算能力</li>
</ul></li>
</ul></li>
<li>研究现状
<ul>
<li>中心化并行训练（PS-Worker）
<ul>
<li>工作流程
<ul>
<li>作为中心化的 PS 将在本地维护一个全局模型， 负责更新 Worker
上的本地模型。 在每次迭代训练中，训练数据集会被分割并分配给每个 Worker
进行本地训练，完成训练后计算梯度值并将其推送给 PS。 PS 收到来自各个
Worker 的梯度后，使用随机梯度下降法或其他优化算法更新全局模型。随后
Worker 会从 PS 拉取最新的模型以便进入下一次迭代训练。</li>
</ul></li>
<li>演进历程
<ul>
<li>第一代
<ul>
<li>基于Memcached的分布式参数存储</li>
</ul></li>
<li>第二代
<ul>
<li>DistBelief</li>
</ul></li>
<li>第三代
<ul>
<li>PS-Lite通用架构</li>
</ul></li>
</ul></li>
<li>优化方案
<ul>
<li>数据/模型并行
<ul>
<li>SINGA</li>
<li>CNTK</li>
</ul></li>
<li>重叠计算/通信
<ul>
<li>WFBP</li>
<li>BytePS</li>
</ul></li>
<li>弹性参数服务器
<ul>
<li>EPS</li>
<li>Pathways</li>
</ul></li>
</ul></li>
</ul></li>
<li>去中心化并行训练（AllReduce）
<ul>
<li>工作流程
<ul>
<li>不同于参数服务器模式需要 PS 和Worker 两类工作节点，在 AllReduce
模式中只需要 Worker 节点， 模型参数或梯度只在 Worker 之间传输，每个
Worker 都是平等的</li>
<li>将所有 Worker连接成一个逻辑环，每个 Worker
把本地计算得到的梯度划分成 N
份并依次把自己的梯度同步给下一个邻居Worker，总共经过 2*(N-1)轮同步，
才能够完成所有 Worker 的梯度更新</li>
</ul></li>
<li>优化方案
<ul>
<li>分层同步
<ul>
<li>Hierarchical-AllReduce</li>
<li>2D-Torus AllReduce</li>
<li>HiPS</li>
</ul></li>
<li>异构问题
<ul>
<li>BlueConnect</li>
<li>Blink</li>
<li>FlexReduce</li>
<li>DS-Sync</li>
</ul></li>
</ul></li>
</ul></li>
<li>网内聚合技术
<ul>
<li>基于可编程网络设备（如可编程交换机、 FPGA 或智能网卡等）
的计算能力加速各种聚合应用</li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/3.png" srcset="/img/loading.gif" lazyload alt="常见网内聚合解决方案对比">
<figcaption aria-hidden="true">常见网内聚合解决方案对比</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li>研究内容
<ul>
<li>基于 Ring-AllReduce 与网内聚合的混合同步算法</li>
<li>大规模分布式机器学习训练的网内聚合CINA链式扩展策略</li>
</ul></li>
</ul>
<h1 id="第二章-相关技术概述">第二章 相关技术概述</h1>
<ul>
<li>分布式并行训练策略
<ul>
<li>数据并行训练
<ul>
<li>核心原理​
<ul>
<li>数据集切分到不同计算节点，每个节点持有完整模型副本进行本地训练</li>
</ul></li>
<li>同步机制
<ul>
<li>PS-Worker模式：Worker推送梯度至PS，PS聚合后广播更新（易带宽瓶颈）</li>
<li>AllReduce模式：节点间直接同步梯度（无中心节点）</li>
</ul></li>
<li>挑战
<ul>
<li>通信开销随节点数增长，可能引发掉队者问题</li>
</ul></li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/4.png" srcset="/img/loading.gif" lazyload alt="分布式数据并行训练">
<figcaption aria-hidden="true">分布式数据并行训练</figcaption>
</figure></li>
</ul></li>
<li>模型并行训练
<ul>
<li>核心原理
<ul>
<li>模型按层/神经元切分到不同节点</li>
</ul></li>
<li>划分策略
<ul>
<li>横向按层划分​
<ul>
<li>节点负责特定网络层（层数多时适用）</li>
</ul></li>
<li>纵向跨层划分
<ul>
<li>单层参数矩阵分块（神经元多时适用）</li>
</ul></li>
<li>混合划分
<ul>
<li>结合横向与纵向策略</li>
</ul></li>
</ul></li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/5.png" srcset="/img/loading.gif" lazyload alt="分布式模型并行训练">
<figcaption aria-hidden="true">分布式模型并行训练</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li>网内聚合
<ul>
<li>可编程交换机
<ul>
<li>核心架构
<ul>
<li>RMT（可重构匹配表）模型支撑数据包处理</li>
</ul></li>
<li>关键部件
<ul>
<li>解析器​：提取/修改数据包头部字段</li>
<li>匹配部件​：执行流表规则（匹配+动作集）</li>
<li>编程语言：P4定义数据包处理流程</li>
</ul></li>
<li>挑战限制
<ul>
<li>聚合流量可能高达数十个 Gb 甚至 Tb，远超 RMT 交换机的内存容量</li>
<li>SRAM/TCAM内存仅数十MB，需精细管理</li>
</ul></li>
</ul></li>
<li>网内聚合的应用
<ul>
<li>分布式机器学习
<ul>
<li>减少网络流量与主机计算负担</li>
</ul></li>
<li>类MapReduce应用
<ul>
<li>使用网内聚合在交换机侧完成部分数据的规约任务， 在 Reduce
阶段减少发送给 Reducer 节点的数据， 降低 Incast 现象出现的概率</li>
</ul></li>
<li>分布式存储修复
<ul>
<li>减少数据传输量、提高修复效率、降低存储节点负载</li>
</ul></li>
</ul></li>
</ul></li>
<li>集合通信及分布式训练框架
<ul>
<li>集合通信
<ul>
<li>Broadcast
<ul>
<li>单节点数据分发至所有节点</li>
</ul></li>
<li>Gather/AllGather​
<ul>
<li>收集所有节点数据</li>
</ul></li>
<li>Reduce/AllReduce
<ul>
<li>跨节点数据聚合（求和/最大值等）</li>
</ul></li>
<li>Scatter/Reduce-Scatter
<ul>
<li>数据分块分发与局部聚合</li>
</ul></li>
</ul></li>
<li>分布式训练框架
<ul>
<li>TensorFlow​
<ul>
<li>数据流图架构，支持gRPC通信</li>
<li>高级API与低级API灵活适配</li>
</ul></li>
<li>PyTorch
<ul>
<li>动态计算图，支持GLOO/MPI/NCCL通信后端</li>
</ul></li>
<li>MXNet
<ul>
<li>跨语言支持，轻量级分布式训练</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h1 id="第三章-基于-ring-allreduce-与网内聚合的混合同步算法设计">第三章
基于 Ring-AllReduce 与网内聚合的混合同步算法设计</h1>
<ul>
<li>问题分析
<ul>
<li>Ring-AllReduce 同步算法
<ul>
<li>算法逻辑
<ul>
<li>所有计算节点
在逻辑拓扑上形成一个环，计算节点反向传播结束得到梯度后，会将梯度均匀切分成
n
份。每个节点错开将其中一份梯度发送给右邻居，并接收左邻居的一份梯度与本地梯度进行聚合。然后每个节点再将上一步聚合好的一份梯度继续发送给右邻居，重复上一步的操作。在进行
n-1步后，每个节点都将得到一份聚合了所有节点梯度的结果。
之后每个节点继续将聚合结果发送给右邻居，同时接收左邻居的聚合结果并覆盖本地位置的梯度。然后每个节点再将上一步接收的聚合结果继续发送给右邻居，重复上一步的操作。在进行
n-1 步后，每个节点都将得到整份聚合了所有节点梯度的结果</li>
</ul></li>
<li>优势
<ul>
<li>通信量固定（不超过2倍模型大小）</li>
</ul></li>
<li>缺陷
<ul>
<li>通信延迟随节点数线性增长</li>
</ul></li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/6.png" srcset="/img/loading.gif" lazyload alt="Ring-AllReduce 同步算法示意图">
<figcaption aria-hidden="true">Ring-AllReduce
同步算法示意图</figcaption>
</figure></li>
</ul></li>
<li>网内聚合算法
<ul>
<li>算法逻辑
<ul>
<li>计算节点将梯度打包发送给可编程交换机，可编程交换机接收到梯度数据包之后寻找到对应的聚合器进行聚合。当聚合器识别到聚合完所有计算节点的梯度数据包之后，将对聚合结果进行打包并广播给所有计算节点</li>
</ul></li>
<li>优势
<ul>
<li>将主机侧的聚合操作卸载到交换机侧，在网络中减少聚合流量，降低通信开销</li>
</ul></li>
<li>缺陷
<ul>
<li>多任务争抢交换机内存导致效率下降</li>
</ul></li>
<li>内存分配机制对比
<ul>
<li>静态固定内存分配
<ul>
<li>每个任务在可编程交换机中平均分配一块内存，任务之间相互隔离，互不影响</li>
<li>内存利用率低</li>
</ul></li>
<li>动态共享内存分配
<ul>
<li>内存由多个任务共享，每个任务的梯度数据包按照先到先服务的机制占用聚合器。此外
ESA 还能通过优先级机制抢占已被占用的聚合器</li>
<li>需要PS节点容错，有可能将回退成 PS-Worker 的训练模式</li>
</ul></li>
<li>在多训练任务的场景下采用动态共享内存分配模式更能充分发挥网内聚合的性能</li>
</ul></li>
</ul></li>
</ul></li>
<li>混合同步算法设计(RA-INA)
<ul>
<li>整体概述
<ul>
<li>主要流程
<ol type="1">
<li>初始化工作，
在同步开始时，可编程交换机将内存划分成大小相同的聚合器，
每个聚合器负责一组梯度的聚合任务。计算节点将梯度切分成大小与聚合器内存相同的梯度块，并将梯度块分组，
然后对按组将梯度块打包成梯度数据包发送到可编程交换机中进行网内聚合</li>
<li>当某个节点的梯度数据包在可编程交换机中寻找到连续的 n
个聚合器时，该梯度数据包将批量占领这 n
个聚合器，并将梯度缓存在对应的聚合器中</li>
<li>部分梯度块将转而执行网内聚合算法，并在完成所有计算节点的梯度聚合工作之后，可编程交换机会将聚合结果广播给每个计算节点</li>
<li>若没有在可编程交换机中寻找到满足要求的聚合器组，则该梯度数据包所在的梯度组将继续执行算法的下一步</li>
<li>如果之后 算法执行到 n-1 步之后，即AllGather 操作时，
该梯度组将不再尝试寻找空闲聚合器， 继续完成 AllGather 操作</li>
</ol></li>
<li>核心理念
<ul>
<li>动态混合执行
<ul>
<li>梯度同步过程在 ​Ring-AllReduce​ 与
​网内聚合间动态切换，通过交换机内存占用状态决策执行路径</li>
</ul></li>
<li>批量抢占机制
<ul>
<li>梯度数据包到达交换机时，尝试批量占领与计算节点数相等的聚合器组（非单个抢占），成功则切换网内聚合</li>
</ul></li>
</ul></li>
<li>过程示例
<ul>
<li>单任务
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/7.png" srcset="/img/loading.gif" lazyload alt="单任务时 RA-INA 算法的同步过程示例">
<figcaption aria-hidden="true">单任务时 RA-INA
算法的同步过程示例</figcaption>
</figure></li>
</ul></li>
<li>多任务
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/8.png" srcset="/img/loading.gif" lazyload alt="多任务时 RA-INA 算法的同步过程示例">
<figcaption aria-hidden="true">多任务时 RA-INA
算法的同步过程示例</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>主机侧逻辑设计
<ul>
<li>数据预处理
<ul>
<li>梯度切分
<ul>
<li>按 ​64个梯度元素/块切分</li>
<li>n个梯度块为一组（n=节点数），形成逻辑分组</li>
</ul></li>
<li>数据包格式
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/9.png" srcset="/img/loading.gif" lazyload alt="梯度数据包的包格式">
<figcaption aria-hidden="true">梯度数据包的包格式</figcaption>
</figure></li>
</ul></li>
</ul></li>
<li>通信控制逻辑
<ul>
<li>滑动窗口
<ul>
<li>每组梯度独立维护状态机，完成一组后滑动至下一组</li>
</ul></li>
<li>浮点处理
<ul>
<li>梯度缩放为32位整数传输，交换机聚合后主机侧还原为浮点数</li>
</ul></li>
<li>ACK响应逻辑
<ul>
<li>接收聚合结果后返回ACK，触发交换机释放聚合器</li>
<li>超时未收到ACK则重传数据包</li>
</ul></li>
</ul></li>
</ul></li>
<li>交换机侧逻辑设计
<ul>
<li>聚合器结构设计
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/10.png" srcset="/img/loading.gif" lazyload alt="聚合器结构">
<figcaption aria-hidden="true">聚合器结构</figcaption>
</figure></li>
</ul></li>
<li>处理流程
<ul>
<li>聚合器匹配
<ul>
<li>根据包头<code>job_id</code>和<code>group_index</code>定位聚合器组​</li>
<li>若未占用，遍历寻找连续n个空闲聚合器​</li>
</ul></li>
<li><strong>数据聚合</strong>​
<ul>
<li>校验<code>bitmap</code>防止重复聚合</li>
<li>整型梯度累加到<code>data</code>区，更新<code>bitmap</code>和<code>counter</code></li>
</ul></li>
<li><strong>广播触发</strong>
<ul>
<li>当<code>counter == n</code>且<code>bitmap</code>全1时，广播聚合结果</li>
</ul></li>
</ul></li>
</ul></li>
<li>可靠性设计
<ul>
<li>丢包处理机制
<ul>
<li>主机→交换机丢包
<ul>
<li>2MSL未收到ACK</li>
<li>重传梯度数据包</li>
</ul></li>
<li>交换机→主机丢包
<ul>
<li>2MSL未收到结果ACK</li>
<li>交换机重发聚合结果</li>
</ul></li>
<li>ACK丢包
<ul>
<li>重复数据包触发bitmap校验</li>
<li>丢弃重复包，补发ACK</li>
</ul></li>
</ul></li>
</ul></li>
<li>实验分析
<ul>
<li>网内聚合性能影响因素分析
<ul>
<li>内存利用率高</li>
<li>任务数影响小</li>
<li>内存不足性能衰减小</li>
</ul></li>
<li>单任务时的训练吞吐量对比
<ul>
<li>比Ring-AllReduce ​吞吐量提升57%</li>
<li>比PS-Worker 加速2.0倍</li>
</ul></li>
<li>多任务时的平均任务完成时间对比
<ul>
<li>RA-INA比SwitchML ​JCT降低25.4%</li>
<li>RA-INA比Ring-AllReduce ​JCT降低18.1%</li>
</ul></li>
</ul></li>
</ul>
<h1 id="第四章-大规模分布式训练的网内聚合扩展策略设计">第四章
大规模分布式训练的网内聚合扩展策略设计</h1>
<ul>
<li>问题分析
<ul>
<li>HINA分层网内聚合扩展策略
<ul>
<li>同步流程
<ul>
<li>首先所有服务器中的计算节点将梯度数据包向上发送到各自所在的 ToR
交换机进行第一次网内聚合。 之后 ToR
交换机继续向上将聚合好的梯度数据包发送给 ToR 交换机所连接的 AGG 交换机，
进行第二次网内聚合。 然后 AGG
交换机仍然将聚合好的梯度数据包向上发送给所连接的
Core交换机进行最后一次网内聚合。 最后作为根节点的 Core
交换机将得到所有计算节点梯度数据包的聚合结果， 并原路进行组播。
在每一层中，
该层的交换机都将进一步组播梯度数据包，最终到达每个计算节点，
完成本次梯度同步</li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/11.png" srcset="/img/loading.gif" lazyload alt="HINA 在 Fat-Tree 网络拓扑中构建的聚合树">
<figcaption aria-hidden="true">HINA 在 Fat-Tree
网络拓扑中构建的聚合树</figcaption>
</figure></li>
</ul></li>
<li>缺陷
<ul>
<li>需替换多层级交换机（ToR+AGG+Core），部署成本高</li>
</ul></li>
</ul></li>
<li>MTINA多树网内聚合扩展策略
<ul>
<li>同步流程
<ul>
<li>MTINA 将根据参与训练任务的计算节点分布情况，以 Core
交换机为根节点初始化生成多棵聚合树。 与 HINA 中生成的聚合树相同， MTINA
中每棵聚合树的叶子节点均为计算节点，非叶子节点均为具有计算功能的可编程交换机</li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/12.png" srcset="/img/loading.gif" lazyload alt="MTINA 在 Fat-Tree 网络拓扑中构建的聚合树">
<figcaption aria-hidden="true">MTINA 在 Fat-Tree
网络拓扑中构建的聚合树</figcaption>
</figure></li>
</ul></li>
<li>缺陷
<ul>
<li>构建多聚合树需全网可编程交换机，成本激增</li>
</ul></li>
</ul></li>
</ul></li>
<li>链式网内聚合扩展策略设计
<ul>
<li>整体结构(以Spine Leaf 网络架构为例)
<ul>
<li>网络拓扑​
<ul>
<li>Spine-Leaf架构，仅替换Leaf层为可编程交换机</li>
</ul></li>
<li>四阶段流水线：
<ol type="1">
<li>机内Ring-Reduce​
<ul>
<li>GPU间高带宽聚合梯度至Master Node</li>
</ul></li>
<li>机架内INA
<ul>
<li>ToR交换机聚合本机架Master Node数据</li>
</ul></li>
<li>机架间链式聚合​
<ul>
<li>ToR交换机形成流水线，跨机架迭代聚合</li>
</ul></li>
<li>结果组播
<ul>
<li>最终聚合结果广播回Master Node</li>
</ul></li>
</ol></li>
</ul></li>
<li>机内聚合策略
<ul>
<li>主节点选择​
<ul>
<li>规则
<ul>
<li>每台服务器固定选择末位GPU为Master Node</li>
</ul></li>
<li>作用
<ul>
<li>作为机内聚合结果缓存点与机间通信代理。</li>
</ul></li>
</ul></li>
<li>Ring-Reduce流水线​
<ul>
<li>执行流程
<ul>
<li>梯度切分
<ul>
<li>每GPU梯度分k块</li>
</ul></li>
<li>Reduce-Scatter​
<ol type="1">
<li><span class="math inline"><em>G</em><sub>(<em>i</em>, 0)</sub> → <em>G</em><sub>(<em>i</em>, 1)</sub></span>发送块0，同时接收<span class="math inline"><em>G</em><sub>(<em>i</em>, 3)</sub> → <em>G</em><sub>(<em>i</em>, 0)</sub></span>块3</li>
<li><span class="math inline"><em>G</em><sub>(<em>i</em>, 1)</sub> → <em>G</em><sub>(<em>i</em>, 2)</sub></span>发送块1，同时接收<span class="math inline"><em>G</em><sub>(<em>i</em>, 0)</sub> → <em>G</em><sub>(<em>i</em>, 1)</sub></span>块0</li>
<li>…</li>
</ol></li>
<li>聚合终点​
<ul>
<li>经(n+k-2)步，所有梯度块聚合至<span class="math inline"><em>G</em><sub>(<em>i</em>, 3)</sub></span></li>
</ul></li>
</ul></li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/13.png" srcset="/img/loading.gif" lazyload alt="CINA 算法使用 4 个 GPU 进行 Ring-Reduce 操作的分解过程">
<figcaption aria-hidden="true">CINA 算法使用 4 个 GPU 进行 Ring-Reduce
操作的分解过程</figcaption>
</figure></li>
</ul></li>
<li>延迟公式​
<ul>
<li><span class="math inline">$T_{机内RR} = \frac{(n+k-2)K}{kB_{dtd}} +
(n+k-2)\alpha_{dtd}$</span>（n=GPU数,K=梯度大小n=GPU数,
K=梯度大小n=GPU数,K=梯度大小）</li>
</ul></li>
</ul></li>
<li>机架内聚合策略
<ul>
<li>ToR交换机
<ul>
<li>核心功能
<ul>
<li>聚合本机架内所有Master Node梯度</li>
<li>生成机架级聚合结果</li>
</ul></li>
</ul></li>
<li>通信重叠优化
<ul>
<li>Master Node在接收第一份聚合梯度后立即发送至ToR交换机</li>
<li>覆盖机内剩余通信时间
<ul>
<li><span class="math inline">$T_{重叠} \leq T_{机内RR} -
\left(n-1)\times( \frac{K}{kB_{htl}} + \alpha_{htl} \right)$</span></li>
</ul></li>
</ul></li>
</ul></li>
<li>机架间聚合策略
<ul>
<li>链式聚合原理
<ul>
<li>Leaf交换机按Pod编号串联</li>
<li>工作流程
<ol type="1">
<li><span class="math inline"><em>L</em><em>S</em><sub>0</sub></span>：发送本地聚合结果<span class="math inline"><em>g</em>2<sub><em>t</em></sub><sup>(0)</sup></span>​至<span class="math inline"><em>L</em><em>S</em><sub>1</sub></span></li>
<li><span class="math inline"><em>L</em><em>S</em><sub>1</sub></span>​：计算<span class="math inline"><em>g</em>3<sub><em>t</em></sub><sup>(1)</sup>​ = <em>g</em>2<sub><em>t</em></sub><sup>(1)</sup>​ + <em>g</em>2<sub><em>t</em></sub><sup>(0)</sup></span>，发送至<span class="math inline"><em>L</em><em>S</em><sub>2</sub></span></li>
<li><span class="math inline"><em>L</em><em>S</em><sub>2</sub></span>​：计算<span class="math inline"><em>g</em>3<sub><em>t</em></sub><sup>(2)</sup>​ = <em>g</em>2<sub><em>t</em></sub><sup>(2)</sup>​ + <em>g</em>3<sub><em>t</em></sub><sup>(1)</sup></span>，发送至<span class="math inline"><em>L</em><em>S</em><sub>3</sub></span></li>
<li><span class="math inline"><em>L</em><em>S</em><sub>3</sub></span>​：获得全局聚合结果<span class="math inline"><em>g</em>3<sub><em>t</em></sub>​</span></li>
</ol></li>
</ul></li>
<li>通信重叠优化
<ul>
<li><span class="math inline">$T_{CINA}=T_{机内RR}-T_{重叠}+\frac{K}{B_{htl}}+\alpha_{htl}+(L-1)\times(\frac{K}{kB_{lts}})+\frac{K}{kB_{min}}+\alpha_{min}$</span></li>
</ul></li>
</ul></li>
</ul></li>
<li>仿真分析
<ul>
<li>理论通信开销推导与对比
<ul>
<li>Ring-AllReduce
<ul>
<li><span class="math inline">$T_{Ring}=2(N-1)\times(\frac{K}{NB_{min}}+\alpha_{min})$</span></li>
</ul></li>
<li>PS-Worker
<ul>
<li><span class="math inline">$T_{PS}=(k+1)\times(\frac{K}{kB_{min}})+2\alpha_{min}$</span></li>
</ul></li>
<li>HINA
<ul>
<li><span class="math inline">$T_{HINA}=T_{机内RR}-T_{重叠}+\frac{K}{B_{htl}}+\alpha_{htl}+2\times(\frac{K}{kB_{lts}}+\alpha_{lts})+\frac{K}{kB_{min}}+\alpha_{min}$</span></li>
</ul></li>
<li>MTINA
<ul>
<li><span class="math inline">$T_{MTINA}=(k+1)\times(S+1)\times(\frac{K}{kSB_{min}})+(S+1)\times\alpha_{min}$</span></li>
</ul></li>
<li>优势对比
<ul>
<li>CINA
只在服务器与上层交换机间存在多对一通信的压力，并不会一层一层的积累通信压力</li>
<li>CINA 不需要像 HINA 和 MTINA 中将 Leaf 层和 Spine
层的交换机替换为可编程交换机，本设计只需要更换 Leaf
层的交换机，降低了部署难度和成本</li>
<li>三层网络最大支持节点数：​CINA 14,338 &gt; HINA 3,600</li>
<li>相同的节点规模下， CINA 的部署成本也比 HINA 和 MTINA 更有优势</li>
</ul></li>
</ul></li>
<li>仿真平台搭建
<ul>
<li>平台架构设计​
<ol type="1">
<li>真实VGG19/ResNet50训练数据</li>
<li>NS3构建可扩展Spine-Leaf网络。</li>
<li>实现五种对比算法</li>
<li>丢包率与聚合正确性监控</li>
</ol></li>
<li>关键参数配置
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/18.png" srcset="/img/loading.gif" lazyload alt="仿真参数配置">
<figcaption aria-hidden="true">仿真参数配置</figcaption>
</figure></li>
</ul></li>
<li>Trace激励源设计​
<ul>
<li>PyTorch Profiler + 自定义Hook</li>
</ul></li>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/19.png" srcset="/img/loading.gif" lazyload alt="仿真平台搭建流程">
<figcaption aria-hidden="true">仿真平台搭建流程</figcaption>
</figure></li>
</ul></li>
<li>仿真结果与分析
<ul>
<li>训练时间对比
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/14.png" srcset="/img/loading.gif" lazyload alt="VGG19 和 ResNet50 的训练时间对比">
<figcaption aria-hidden="true">VGG19 和 ResNet50
的训练时间对比</figcaption>
</figure></li>
</ul></li>
<li>吞吐量对比
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/15.png" srcset="/img/loading.gif" lazyload alt="VGG19 和 ResNet50 的训练吞吐量对比">
<figcaption aria-hidden="true">VGG19 和 ResNet50
的训练吞吐量对比</figcaption>
</figure></li>
</ul></li>
<li>拓展效率对比
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/16.png" srcset="/img/loading.gif" lazyload alt="VGG19 和 ResNet50 的训练拓展效率对比">
<figcaption aria-hidden="true">VGG19 和 ResNet50
的训练拓展效率对比</figcaption>
</figure></li>
</ul></li>
<li>加速比对比
<ul>
<li><figure>
<img src="/2025/07/05/%E5%9F%BA%E4%BA%8E%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%A0%E9%80%9F%E7%AD%96%E7%95%A5%E7%A0%94%E7%A9%B6/17.png" srcset="/img/loading.gif" lazyload alt="VGG19 和 ResNet50 的训练加速比对比">
<figcaption aria-hidden="true">VGG19 和 ResNet50
的训练加速比对比</figcaption>
</figure></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h1 id="第五章-总结与展望">第五章 总结与展望</h1>
<ul>
<li>总结
<ul>
<li>RA-INA混合同步算法
<ul>
<li>解决痛点
<ul>
<li>多任务争抢交换机内存导致的效率下降</li>
</ul></li>
<li>工作机制
<ul>
<li>动态共享内存
<ul>
<li>任务按梯度组抢占聚合器</li>
</ul></li>
<li>混合执行逻辑​
<ul>
<li>Ring-AllReduce容错 + 网内聚合加速</li>
</ul></li>
</ul></li>
</ul></li>
<li>CINA链式扩展策略
<ul>
<li>解决痛点
<ul>
<li>大规模分布式训练场景下网内聚合的扩展性问题</li>
</ul></li>
<li>工作机制
<ul>
<li>多阶段流水线
<ul>
<li>机内Ring-Reduce → ToR层链式聚合</li>
</ul></li>
<li>扁平化的聚合结构</li>
</ul></li>
</ul></li>
</ul></li>
<li>展望
<ul>
<li>同步算法对丢包容忍性</li>
<li>跨交换机甚至跨机架的实机实验平台</li>
<li>网内聚合应用在分布式模型并行训练场景，研究异步训练下的网内聚合算法设计</li>
<li>对于其他的可编程网络设备研究其网内聚合的分布式机器学习加速策略</li>
</ul></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%9C%A8%E7%BD%91%E8%AE%A1%E7%AE%97/" class="category-chain-item">在网计算</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%8E%9F%E5%88%9B/" class="print-no-link">#原创</a>
      
        <a href="/tags/%E5%9C%A8%E7%BD%91%E8%AE%A1%E7%AE%97/" class="print-no-link">#在网计算</a>
      
        <a href="/tags/2025/" class="print-no-link">#2025</a>
      
        <a href="/tags/%E7%BD%91%E5%86%85%E8%81%9A%E5%90%88/" class="print-no-link">#网内聚合</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>基于网内聚合的分布式机器学习加速策略研究</div>
      <div>http://example.com/2025/07/05/基于网内聚合的分布式机器学习加速策略研究/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Wsdbybyd</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年7月5日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/07/16/ATP%EF%BC%9AIn-network%20Aggregation%20for%20Multi-tenant%20Learning/" title="ATP：In-network Aggregation for Multi-tenant Learning">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ATP：In-network Aggregation for Multi-tenant Learning</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/06/29/%E5%9F%BA%E4%BA%8E%E5%9C%A8%E7%BD%91%E8%AE%A1%E7%AE%97%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95/" title="基于在网计算的分布式系统加速方法">
                        <span class="hidden-mobile">基于在网计算的分布式系统加速方法</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"52Z5Ks9jpkkA8Nk9gIMDFgGD-gzGzoHsz","appKey":"CsGFqxm0pVH3GDRIHhk6l63y","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
